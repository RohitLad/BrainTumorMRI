{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juEA9J6JZ2Uj",
        "colab_type": "text"
      },
      "source": [
        "# Brain Tumor Auto-Segmentation for MRI\n",
        "\n",
        "## Description\n",
        "\n",
        "Magnetic Resonance Imaging (MRI) is an imaging technique which is used to obeserve a variety of diseases and body parts. The atoms of body parts are subjected to magnetic field to which they emmit radio waves. These radio waves are then measured to get an image of the particular body part, this is how [MRI](https://en.wikipedia.org/wiki/Magnetic_resonance_imaging) works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJoHC1dbZ2Um",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "5dc3fc9a-0877-48fd-ea2e-03f2e5df90af"
      },
      "source": [
        "# Just colab things\n",
        "onColab = True\n",
        "if onColab:\n",
        "  !rm -rf repo\n",
        "  !git clone https://github.com/RohitLad/BrainTumorMRI.git repo\n",
        "  repoDir = 'repo/'\n",
        "  %tensorflow_version 1.15.0\n",
        "else:\n",
        "  repoDir = ''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'repo'...\n",
            "remote: Enumerating objects: 70, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/70)\u001b[K\rremote: Counting objects:   2% (2/70)\u001b[K\rremote: Counting objects:   4% (3/70)\u001b[K\rremote: Counting objects:   5% (4/70)\u001b[K\rremote: Counting objects:   7% (5/70)\u001b[K\rremote: Counting objects:   8% (6/70)\u001b[K\rremote: Counting objects:  10% (7/70)\u001b[K\rremote: Counting objects:  11% (8/70)\u001b[K\rremote: Counting objects:  12% (9/70)\u001b[K\rremote: Counting objects:  14% (10/70)\u001b[K\rremote: Counting objects:  15% (11/70)\u001b[K\rremote: Counting objects:  17% (12/70)\u001b[K\rremote: Counting objects:  18% (13/70)\u001b[K\rremote: Counting objects:  20% (14/70)\u001b[K\rremote: Counting objects:  21% (15/70)\u001b[K\rremote: Counting objects:  22% (16/70)\u001b[K\rremote: Counting objects:  24% (17/70)\u001b[K\rremote: Counting objects:  25% (18/70)\u001b[K\rremote: Counting objects:  27% (19/70)\u001b[K\rremote: Counting objects:  28% (20/70)\u001b[K\rremote: Counting objects:  30% (21/70)\u001b[K\rremote: Counting objects:  31% (22/70)\u001b[K\rremote: Counting objects:  32% (23/70)\u001b[K\rremote: Counting objects:  34% (24/70)\u001b[K\rremote: Counting objects:  35% (25/70)\u001b[K\rremote: Counting objects:  37% (26/70)\u001b[K\rremote: Counting objects:  38% (27/70)\u001b[K\rremote: Counting objects:  40% (28/70)\u001b[K\rremote: Counting objects:  41% (29/70)\u001b[K\rremote: Counting objects:  42% (30/70)\u001b[K\rremote: Counting objects:  44% (31/70)\u001b[K\rremote: Counting objects:  45% (32/70)\u001b[K\rremote: Counting objects:  47% (33/70)\u001b[K\rremote: Counting objects:  48% (34/70)\u001b[K\rremote: Counting objects:  50% (35/70)\u001b[K\rremote: Counting objects:  51% (36/70)\u001b[K\rremote: Counting objects:  52% (37/70)\u001b[K\rremote: Counting objects:  54% (38/70)\u001b[K\rremote: Counting objects:  55% (39/70)\u001b[K\rremote: Counting objects:  57% (40/70)\u001b[K\rremote: Counting objects:  58% (41/70)\u001b[K\rremote: Counting objects:  60% (42/70)\u001b[K\rremote: Counting objects:  61% (43/70)\u001b[K\rremote: Counting objects:  62% (44/70)\u001b[K\rremote: Counting objects:  64% (45/70)\u001b[K\rremote: Counting objects:  65% (46/70)\u001b[K\rremote: Counting objects:  67% (47/70)\u001b[K\rremote: Counting objects:  68% (48/70)\u001b[K\rremote: Counting objects:  70% (49/70)\u001b[K\rremote: Counting objects:  71% (50/70)\u001b[K\rremote: Counting objects:  72% (51/70)\u001b[K\rremote: Counting objects:  74% (52/70)\u001b[K\rremote: Counting objects:  75% (53/70)\u001b[K\rremote: Counting objects:  77% (54/70)\u001b[K\rremote: Counting objects:  78% (55/70)\u001b[K\rremote: Counting objects:  80% (56/70)\u001b[K\rremote: Counting objects:  81% (57/70)\u001b[K\rremote: Counting objects:  82% (58/70)\u001b[K\rremote: Counting objects:  84% (59/70)\u001b[K\rremote: Counting objects:  85% (60/70)\u001b[K\rremote: Counting objects:  87% (61/70)\u001b[K\rremote: Counting objects:  88% (62/70)\u001b[K\rremote: Counting objects:  90% (63/70)\u001b[K\rremote: Counting objects:  91% (64/70)\u001b[K\rremote: Counting objects:  92% (65/70)\u001b[K\rremote: Counting objects:  94% (66/70)\u001b[K\rremote: Counting objects:  95% (67/70)\u001b[K\rremote: Counting objects:  97% (68/70)\u001b[K\rremote: Counting objects:  98% (69/70)\u001b[K\rremote: Counting objects: 100% (70/70)\u001b[K\rremote: Counting objects: 100% (70/70), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 70 (delta 10), reused 60 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (70/70), done.\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.15.0`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjf_9X9MZ2Uz",
        "colab_type": "text"
      },
      "source": [
        "## 1. Import Packages andf Functions\n",
        "\n",
        "We would be using the following packages\n",
        "\n",
        "- `numpy` and `pandas` for data manipulation\n",
        "- `keras` for building Deep Learning models\n",
        "- `matplotlib` and `seaborn` for plots\n",
        "- `nibabel` to extract images and labels from dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-94qB4IWZ2U4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5a7a11ee-6123-474e-eebf-0a501835e527"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import h5py\n",
        "from functools import partial\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation, Conv3D, Deconvolution3D, MaxPooling3D, UpSampling3D\n",
        "from keras.engine import Input, Model\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
        "K.set_image_data_format(\"channels_first\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHZZDegtZ2VB",
        "colab_type": "text"
      },
      "source": [
        "## 2. Dataset Description\n",
        "\n",
        "MR images are often encountered in [DICOM format](https://en.wikipedia.org/wiki/DICOM), these images can be processed by using the [pydicom](https://pydicom.github.io/pydicom/stable/getting_started.html) library.\n",
        "\n",
        "In this project, we shall be using data from the [Decathlon 10 Challenge](https://decathlon-10.grand-challenge.org). The data is mostly preprocessed but in real prectise, MRI data has to be significantly preprocessed in order to use it to train our models.\n",
        "\n",
        "The dataset is stored in [NifTI-1 format](https://nifti.nimh.nih.gov/nifti-1/) and we will be using the [NiBabel library](https://github.com/nipy/nibabel) to interact with the files. Every training sample consists of two files:\n",
        "\n",
        "The first file is a 3D image with 4 channels, so basically it is a 4D array of shape (240, 240, 155, 4)\n",
        "\n",
        "- The first three dimensions signify the location (X, Y and Z coordinates) for each point in the 3D volume\n",
        "- The 4th dimension is the values of four different sequences namely:\n",
        "    - FLAIR: \"Fluid Attenuated Inversion Recovery\"\n",
        "    - T1w: \"T1-weighted\"\n",
        "    - t1gd: \"T1-weighted with gadolinium contrast enhancement\"\n",
        "    - T2w: \"T2-weighted\"\n",
        "    \n",
        "The second file is a label file containing of a 3D array of shape (240, 240, 155). The labels are integers corresponding:\n",
        "   - 0: background\n",
        "   - 1: edema\n",
        "   - 2: non-enhancing tumor\n",
        "   - 3: enhancing tumor\n",
        "\n",
        "We have 484 training examples which are then split into 80% training and 20% validation data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C68h_PNZ2VE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specifying the paths\n",
        "DataDir = repoDir+\"Data/\"\n",
        "trainDir = DataDir+'train/'\n",
        "validDir = DataDir+'valid/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBYnaoUuZ2VP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QP0a27F8Z2VQ",
        "colab_type": "text"
      },
      "source": [
        "## 3. Dice Similarity Coefficient\n",
        "\n",
        "A natural candidate that one comes up with as a loss function is the cross-entropy loss function. But this function is not suitable for segmentation tasks since there is a heavy class imbalance as there aren't many positive regions in an MR image dataset.\n",
        "\n",
        "A much more common loss for segmentation tasks is the Dice similarity coefficient (DSC). A DSC measures how similar two regions are or in general, how well two contours overlap.\n",
        "\n",
        "- Dice index ranges from 0 (complete mismatch) to 1 (perfect match)\n",
        "\n",
        "For two sets $A$ and $B$, the DSC is defined as:\n",
        "$$\\text{DSC}(A, B) = 2 \\times \\frac{|A \\cap B|}{|A| + |B|}$$\n",
        "Here, we can interpret $A$ as the prediction for voxel being considered and $B$ being the ground truth.\n",
        "\n",
        "Considering:\n",
        "- $x$: the input image\n",
        "- $f(x)$: the model output (prediction)\n",
        "- $y$ the label (ground truth)\n",
        "\n",
        "$$\\text{DSC}(f, x, y) = 2 \\times\\frac{ \\sum_{i, j} f(x)_{ij} \\times y_{ij} + \\epsilon}{\\sum_{i,j} f(x)_{ij} + \\sum_{i, j} y_{ij} + \\epsilon}$$\n",
        "\n",
        "- $\\epsilon$ is a small number to avoid division by zero\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/328671987/figure/fig4/AS:688210103529478@1541093483784/Calculation-of-the-Dice-similarity-coefficient-The-deformed-contour-of-the-liver-from.ppm\" width=\"30%\">\n",
        "\n",
        "[Image Source](https://www.researchgate.net/figure/Calculation-of-the-Dice-similarity-coefficient-The-deformed-contour-of-the-liver-from_fig4_328671987)\n",
        "\n",
        "\n",
        "The above is a formulation for a single class. Given $\\text{DSC}(f, x, y)$ for a single class, we can think about a multiple class approach.\n",
        "\n",
        "Consider $\\text{DSC}_i(f, x, y)$ be the Dice Coefficient for $i^{th}$ class, we can take an average over $N$ classes and therefore say\n",
        "\n",
        "$$DC(f, x, y) = \\frac{1}{N} \\sum_{i=1}^{L} \\left ( DSC_{i}(f, x, y) \\right )$$\n",
        "\n",
        "Since we want segmentations for each of three classes of conditions: edema, enhancing tumor, non-enhancing tumor, $L$ would be 3.\n",
        "\n",
        "## 4. Soft Dice Loss\n",
        "\n",
        "Since the Dice Similarity Coefficient takes in discrete values, we need an analogous formulation which takes in real valued input. This is where *Soft Dice Loss* comes in:\n",
        "\n",
        "Considering: \n",
        "- $p$: the predictions\n",
        "- $q$: the ground truth (wither 0 or 1) \n",
        "- $\\epsilon$ is a small number to avoid division by zero\n",
        "\n",
        "the *Soft Dice Loss* ${L}_{Dice}$) is given by\n",
        "$$\\mathcal{L}_{Dice}(p, q) = 1 - 2\\times\\frac{\\sum_{i, j} p_{ij}q_{ij} + \\epsilon}{\\left(\\sum_{i, j} p_{ij}^2 \\right) + \\left(\\sum_{i, j} q_{ij}^2 \\right) + \\epsilon}$$\n",
        "\n",
        "and as it is understood, for multiple classes\n",
        "\n",
        "$$\\mathcal{L}_{Dice}(p, q) = 1 - \\frac{1}{N} \\sum_{c=1}^{L} 2\\times\\frac{\\sum_{i, j} p_{cij}q_{cij} + \\epsilon}{\\left(\\sum_{i, j} p_{cij}^2 \\right) + \\left(\\sum_{i, j} q_{cij}^2 \\right) + \\epsilon}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luiYPn7pZ2VR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def diceCoefficient(yTrue, yPred, axis=(1,2,3), eps=1e-5):\n",
        "    \"\"\"\n",
        "    Calculate the dice coefficient over all classes\n",
        "    \n",
        "    yTrue: tensor of ground truth values (numClasses, yDim, yDim, zDim)\n",
        "    yPred: tensor of soft predictions (numClasses, yDim, yDim, zDim)\n",
        "    axis: spatial axes to sum over while computing Numerator and Denominator\n",
        "    eps: small constant to avoid dividing by zero\n",
        "    \n",
        "    returns:\n",
        "    diceCoefficient: computed value of soft dice coefficient\n",
        "    \"\"\"\n",
        "    numerator = 2*K.sum(yTrue*yPred, axis=axis)+eps\n",
        "    denominator = K.sum(yPred, axis=axis)+K.sum(yTrue, axis=axis)+eps\n",
        "    return K.mean(numerator/denominator)\n",
        "\n",
        "def softDiceLoss(yTrue, yPred, axis=(1,2,3), eps=1e-5):\n",
        "    \"\"\"\n",
        "    Calculate the soft dice loss over all classes\n",
        "    \n",
        "    yTrue: tensor of ground truth values (numClasses, yDim, yDim, zDim)\n",
        "    yPred: tensor of soft predictions (numClasses, yDim, yDim, zDim)\n",
        "    axis: spatial axes to sum over while computing Numerator and Denominator\n",
        "    eps: small constant to avoid dividing by zero\n",
        "    \n",
        "    returns:\n",
        "    diceLoss: computed value of soft dice loss\n",
        "    \"\"\"\n",
        "    \n",
        "    numerator = 2*K.sum(yTrue*yPred, axis=axis)+eps\n",
        "    denominator = K.sum(yPred**2, axis=axis)+K.sum(yTrue**2, axis=axis)+eps\n",
        "    return 1. - K.mean(numerator/denominator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u55j4rrmZ2VX",
        "colab_type": "text"
      },
      "source": [
        "## 5. Model: 3D U-Net\n",
        "\n",
        "A [3D U-net](https://arxiv.org/abs/1606.06650) is used for this task which takes advantage of the volumetric shape of MR images and is one of the best performing models for this task. Know more about the architecture from [this paper](https://arxiv.org/abs/1606.06650).\n",
        "\n",
        "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"50%\">\n",
        "\n",
        "\n",
        "Let us create the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63W-2dHJZ2VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet3D:\n",
        "    \n",
        "    def __init__(self, optimizer, lossFunction, inputShape=(4,160,160,16), poolSize=(2,2,2), \n",
        "                 nLabels=3, lr=1e-5, depth=4, nBaseFilters=32, activation='sigmoid', metrics=[], batchNormalization=False, deconvolution=False):\n",
        "        self.optimizer = optimizer\n",
        "        self.lossFunction = lossFunction\n",
        "        self.inputShape = inputShape\n",
        "        self.poolSize = poolSize\n",
        "        self.nLabels = nLabels\n",
        "        self.learningRate = lr\n",
        "        self.depth = depth\n",
        "        self.nBaseFilters = nBaseFilters\n",
        "        self.activation = activation\n",
        "        self.metrics = [metrics] if not isinstance(metrics, list) else metrics\n",
        "        self.deconvolution = deconvolution\n",
        "        self.batchNormalization = batchNormalization\n",
        "        self.levels = []\n",
        "        self.model = None\n",
        "    \n",
        "    def _createConvBlock(self, inputLayer, nFilters, batchNorm=False, instanceNorm=False, kernel=(3,3,3), activation='relu', padding='same', strides=(1,1,1)):\n",
        "        layer = Conv3D(nFilters, kernel, padding=padding, strides=strides)(inputLayer)\n",
        "        return Activation(activation)(layer)\n",
        "    \n",
        "    def _createUpConvBlock(self, nFilters, poolSize, kernelSize=(2,2,2), strides=(2,2,2), deconvolution=False):\n",
        "        if deconvolution:\n",
        "            return Deconvolution3D(filters=nFilters, kernel_size=kernelSize, strides=strides)\n",
        "        else:\n",
        "            return UpSampling3D(size=poolSize)\n",
        "    \n",
        "    def _getCurrFilters(self, depth):\n",
        "        return self.nBaseFilters*(2**depth)\n",
        "    \n",
        "    def createModel(self):\n",
        "        inputs = Input(self.inputShape)\n",
        "        currLayer = inputs\n",
        "        self.levels = []\n",
        "        self.model = None\n",
        "        \n",
        "        for d in range(self.depth):\n",
        "            currFilters = self._getCurrFilters(depth=d)\n",
        "            layer1 = self._createConvBlock(inputLayer=currLayer, nFilters=currFilters, batchNorm=self.batchNormalization)\n",
        "            layer2 = self._createConvBlock(inputLayer=layer1, nFilters=currFilters*2, batchNorm=self.batchNormalization)\n",
        "            if d < self.depth-1:\n",
        "                currLayer = MaxPooling3D(pool_size=self.poolSize)(layer2)\n",
        "                self.levels.append([layer1, layer2, currLayer])\n",
        "            else:\n",
        "                currLayer = layer2\n",
        "                self.levels.append([layer1, layer2])                \n",
        "\n",
        "        for d in reversed(range(self.depth-1)):\n",
        "            upConv = self._createUpConvBlock(nFilters=currLayer._keras_shape[-1], poolSize=self.poolSize, deconvolution=self.deconvolution)(currLayer)\n",
        "            concat = concatenate([upConv, self.levels[d][1]], axis=1)\n",
        "            currFilters = self.levels[d][1]._keras_shape[1]\n",
        "            layer1 = self._createConvBlock(inputLayer=concat, nFilters=currFilters, batchNorm=self.batchNormalization)\n",
        "            currLayer = self._createConvBlock(inputLayer=layer1, nFilters=currFilters, batchNorm=self.batchNormalization)\n",
        "        \n",
        "        finalLayer = Conv3D(self.nLabels, (1,1,1), activation=self.activation)(currLayer)\n",
        "        self.model = Model(inputs=inputs, outputs=finalLayer)\n",
        "        self.model.compile(optimizer=self.optimizer(lr=self.learningRate), loss=self.lossFunction, metrics=self.metrics)\n",
        "        \n",
        "        return self.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ_bLYOGZ2Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stepDecay(epoch, initLR, drop, epochDrop):\n",
        "    return initLR*drop**np.floor((1+epoch)/float(epochDrop))\n",
        "\n",
        "def getCallbacks(modelFile, initLR=1e-4, lrDrop=0.5, lrEpochs=None, lrPatience=50, loggingFile='training.log', verbosity=1, earlystopPatience=None):\n",
        "    callbacks = list()\n",
        "    callbacks.append(ModelCheckpoint(modelFile, save_best_only=True))\n",
        "    callbacks.append(CSVLogger(loggingFile, append=True))\n",
        "    \n",
        "    if lrEpochs:\n",
        "        callbacks.append(LearningRateScheduler(partial(stepDecay, initLR=initLR, drop=lrDrop, epochDrop=lrEpochs)))\n",
        "    else:\n",
        "        callbacks.append(ReduceLROnPlateau(factor=lrDrop, patience=lrPatience, verbose=verbosity))\n",
        "    \n",
        "    if earlystopPatience:\n",
        "        callbacks.append(EarlyStopping(verbose=verbosity, patience=earlystopPatience))\n",
        "    \n",
        "    return callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUb4FK81Z2Vn",
        "colab_type": "text"
      },
      "source": [
        "First of all, the entire preprocessed dataset is stored in the `h5py` format. We shall write a custom Keras `Sequence` class to be used as a `Generator`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXUxLW5CZ2Vn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, baseDir, listIDs, batchSize=1, dim=(160,160,16), nChannels=4, nClasses=3, shuffle=True):\n",
        "    \n",
        "        'Initialization'\n",
        "        self.baseDir = baseDir\n",
        "        self.dim = dim\n",
        "        self.batchSize = batchSize\n",
        "        self.listIDs = listIDs\n",
        "        self.nChannels = nChannels\n",
        "        self.nClasses = nClasses\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = None\n",
        "        self.on_epoch_end()\n",
        "        self.allX = {}\n",
        "        self.ally = {}\n",
        "        self.initData()\n",
        "        \n",
        "    def initData(self):\n",
        "        for ids in self.listIDs:\n",
        "            with h5py.File(self.baseDir+ids,'r') as f:\n",
        "                self.allX[ids] = np.array(f.get('x'))\n",
        "                self.ally[ids] = np.moveaxis(np.array(f.get('y')), 3, 0)[1:]\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.listIDs))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    \n",
        "    def __data_generation(self, tempListIDs):\n",
        "        'Generates data containing batch_size samples' # X : (n_samples, n_channels, *dim)\n",
        "        \n",
        "        # Initialization\n",
        "        X = np.zeros((self.batchSize, self.nChannels, *self.dim), dtype = np.float64)\n",
        "        y = np.zeros((self.batchSize, self.nClasses, *self.dim), dtype=np.float64)\n",
        "        \n",
        "        # Data Generation\n",
        "        for i, ids in enumerate(tempListIDs):\n",
        "            #with h5py.File(self.baseDir+ids, 'r') as f:\n",
        "            #    X[i] = np.array(f.get('x'))\n",
        "            #    y[i] = np.moveaxis(np.array(f.get('y')), 3, 0)[1:]\n",
        "            X[i] = self.allX[ids]\n",
        "            y[i] = self.ally[ids]\n",
        "        return X, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        'Number of batches per epoch'\n",
        "        return int(np.floor(len(self.listIDs)/self.batchSize))\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        'generate a batch of data'\n",
        "        indexes = self.indexes[index*self.batchSize: (index+1)*self.batchSize]\n",
        "        sampleList = [self.listIDs[i] for i in indexes]\n",
        "        X,y = self.__data_generation(sampleList)\n",
        "        return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cjCN-AtZ2Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open(DataDir+'config.json') as file:\n",
        "    config = json.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdsVD9mIZ2Vy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79dca72e-4095-42e5-8c44-fb28b089ab4d"
      },
      "source": [
        "trainGen = DataGenerator(baseDir=trainDir, listIDs=config['train'], batchSize=3, dim=(160,160,16))\n",
        "validGen = DataGenerator(baseDir=validDir, listIDs=config['valid'], batchSize=3, dim=(160,160,16))\n",
        "model = UNet3D(optimizer=Adam, lossFunction=softDiceLoss, metrics=[diceCoefficient]).createModel()\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 4, 160, 160,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 32, 160, 160, 3488        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 160, 160, 0           conv3d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 64, 160, 160, 55360       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 160, 160, 0           conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3D)  (None, 64, 80, 80, 8 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 64, 80, 80, 8 110656      max_pooling3d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 80, 80, 8 0           conv3d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 128, 80, 80,  221312      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 128, 80, 80,  0           conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_2 (MaxPooling3D)  (None, 128, 40, 40,  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 128, 40, 40,  442496      max_pooling3d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 128, 40, 40,  0           conv3d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 256, 40, 40,  884992      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 256, 40, 40,  0           conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling3d_3 (MaxPooling3D)  (None, 256, 20, 20,  0           activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 256, 20, 20,  1769728     max_pooling3d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 256, 20, 20,  0           conv3d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 512, 20, 20,  3539456     activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 512, 20, 20,  0           conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_1 (UpSampling3D)  (None, 512, 40, 40,  0           activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 768, 40, 40,  0           up_sampling3d_1[0][0]            \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 256, 40, 40,  5308672     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 256, 40, 40,  0           conv3d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_10 (Conv3D)              (None, 256, 40, 40,  1769728     activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 256, 40, 40,  0           conv3d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_2 (UpSampling3D)  (None, 256, 80, 80,  0           activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 384, 80, 80,  0           up_sampling3d_2[0][0]            \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_11 (Conv3D)              (None, 128, 80, 80,  1327232     concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 128, 80, 80,  0           conv3d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_12 (Conv3D)              (None, 128, 80, 80,  442496      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 128, 80, 80,  0           conv3d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling3d_3 (UpSampling3D)  (None, 128, 160, 160 0           activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 192, 160, 160 0           up_sampling3d_3[0][0]            \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_13 (Conv3D)              (None, 64, 160, 160, 331840      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 64, 160, 160, 0           conv3d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_14 (Conv3D)              (None, 64, 160, 160, 110656      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 160, 160, 0           conv3d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_15 (Conv3D)              (None, 3, 160, 160,  195         activation_14[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 16,318,307\n",
            "Trainable params: 16,318,307\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYEChC3pZ2V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def trainModel(model, modelFile, trainGen, validGen, stepsPerEpoch, validSteps, initLR=1e-3, \n",
        "               lrDrop=0.5, lrEpochs=None, nEpochs=500, lrPatience=20, earlyStopPatience=None):\n",
        "    \n",
        "    callbacks = getCallbacks(modelFile=modelFile, initLR=initLR, lrDrop=lrDrop,\n",
        "                            lrEpochs=lrEpochs, lrPatience=lrPatience, earlystopPatience=earlyStopPatience)\n",
        "    if onColab:\n",
        "        mp = True\n",
        "        wrks = 16\n",
        "    else:\n",
        "        mp = False\n",
        "        wrks = 1\n",
        "    model.fit_generator(generator=trainGen,\n",
        "                        steps_per_epoch=stepsPerEpoch,\n",
        "                        epochs=nEpochs,\n",
        "                        validation_data=validGen,\n",
        "                        validation_steps=validSteps,\n",
        "                        callbacks=callbacks,\n",
        "                        use_multiprocessing=mp,\n",
        "                        workers=wrks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SILhon8gZ2V7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "8512ce6c-85e6-471f-ec1a-0d7f651594a8"
      },
      "source": [
        "steps_per_epoch = 20\n",
        "n_epochs=10\n",
        "validation_steps = 20\n",
        "\n",
        "model.fit_generator(generator=trainGen,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=n_epochs,\n",
        "        use_multiprocessing=True,\n",
        "        validation_data=validGen,\n",
        "        validation_steps=validation_steps)\n",
        "model.save_weights('my_model_pretrained.hdf5')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 2 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 1/20 [>.............................] - ETA: 13:38 - loss: 0.8880 - diceCoefficient: 0.0915"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 0 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 2/20 [==>...........................] - ETA: 11:17 - loss: 0.8635 - diceCoefficient: 0.1103"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 1 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 3/20 [===>..........................] - ETA: 10:08 - loss: 0.8616 - diceCoefficient: 0.1132"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 3 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 4/20 [=====>........................] - ETA: 9:18 - loss: 0.8515 - diceCoefficient: 0.1202 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 4 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19/20 [===========================>..] - ETA: 10s - loss: 0.7976 - diceCoefficient: 0.1637"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 5 could not be retrieved. It could be because a worker has died.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r20/20 [==============================] - 392s 20s/step - loss: 0.7928 - diceCoefficient: 0.1679 - val_loss: 0.8259 - val_diceCoefficient: 0.1669\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.5292 - diceCoefficient: 0.3788 - val_loss: 0.7171 - val_diceCoefficient: 0.2657\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.3625 - diceCoefficient: 0.5300 - val_loss: 0.7564 - val_diceCoefficient: 0.2372\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.3014 - diceCoefficient: 0.6037 - val_loss: 0.6666 - val_diceCoefficient: 0.3013\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.2471 - diceCoefficient: 0.6724 - val_loss: 0.6508 - val_diceCoefficient: 0.3222\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.1997 - diceCoefficient: 0.7441 - val_loss: 0.7106 - val_diceCoefficient: 0.2687\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.1719 - diceCoefficient: 0.8044 - val_loss: 0.7117 - val_diceCoefficient: 0.2617\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 51s 3s/step - loss: 0.1674 - diceCoefficient: 0.8189 - val_loss: 0.6904 - val_diceCoefficient: 0.3054\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.1645 - diceCoefficient: 0.8245 - val_loss: 0.7365 - val_diceCoefficient: 0.2789\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 50s 3s/step - loss: 0.1643 - diceCoefficient: 0.8261 - val_loss: 0.6229 - val_diceCoefficient: 0.3616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHjQR6WzaZ2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhjRexgjZ2WE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}